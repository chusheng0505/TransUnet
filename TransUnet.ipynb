{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.activations import *\n",
    "from tensorflow.keras.regularizers import *\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "from typing import Union , Tuple , Dict , List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(input_tensor: tf.float32,\n",
    "         filters: int) -> tf.float32:\n",
    "    kernel_size = (3, 3)\n",
    "    padding = 'same'\n",
    "    activation_fn = 'relu'\n",
    "    x = Conv2D(filters=filters,\n",
    "               kernel_size=kernel_size,\n",
    "               padding=padding)(input_tensor)\n",
    "    return Activation(activation_fn)(x)\n",
    "\n",
    " \n",
    "\n",
    "def multihead_attention(input_tensor: tf.float32,\n",
    "                        num_heads: int,\n",
    "                        dims: int) -> tf.float32:\n",
    "    dropout_rate = 0.1\n",
    "    x = MultiHeadAttention(num_heads=num_heads,\n",
    "                           key_dim=dims,\n",
    "                           dropout=dropout_rate)(input_tensor, input_tensor)\n",
    "    x = Add()([x, input_tensor])\n",
    "    return LayerNormalization()(x)\n",
    "\n",
    "\n",
    "\n",
    "def TransBlock(input_tensor: tf.float32,\n",
    "               num_heads: int,\n",
    "               dims: int,\n",
    "               filters: int) -> tf.float32:\n",
    "    x = multihead_attention(input_tensor=input_tensor,\n",
    "                            num_heads=num_heads,\n",
    "                            dims=dims)\n",
    "    x = conv(input_tensor=x, filters=filters)\n",
    "    x = Add()([input_tensor, x])\n",
    "    return LayerNormalization()(x)\n",
    " \n",
    "\n",
    "def TransUnet(height: int,\n",
    "              width: int,\n",
    "              color_channels: int,\n",
    "              num_classes: int,\n",
    "              n_transblock: int) -> tf.float32:\n",
    "\n",
    "    '''\n",
    "    @params :\n",
    "    1. n_transblock : numbers of transformer blocks in model\n",
    "\n",
    "    note : upsample is replaced by conv2dTranspose\n",
    "    '''\n",
    "    pool_size = (2, 2)\n",
    "    kernel_size = (3, 3)\n",
    "    strides = (2, 2)\n",
    "    padding = 'same'\n",
    "\n",
    "    input_shape = (height, width, color_channels)\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x = conv(input_tensor=inputs, filters=128)\n",
    "    out1 = MaxPooling2D(pool_size=pool_size)(x)\n",
    "    x = conv(input_tensor=out1, filters=256)\n",
    "    out2 = MaxPooling2D(pool_size=pool_size)(x)\n",
    "    x = conv(input_tensor=out2, filters=512)\n",
    "    out3 = MaxPooling2D(pool_size=pool_size)(x)\n",
    "    out3 = BatchNormalization()(out3)\n",
    "    \n",
    "    \n",
    "    x = out3\n",
    "    for _ in range(n_transblock):\n",
    "        x = TransBlock(input_tensor=x, num_heads=12, dims=512, filters=512)\n",
    "    x = MaxPooling2D(pool_size=pool_size)(x)\n",
    "    x = conv(input_tensor=x, filters=512)\n",
    "    x = Conv2DTranspose(filters=512,\n",
    "                        kernel_size=kernel_size,\n",
    "                        strides=strides,\n",
    "                        padding=padding)(x)\n",
    "    x = Concatenate()([x, out3])\n",
    "    x = conv(input_tensor=x, filters=256)\n",
    "    x = Conv2DTranspose(filters=256,\n",
    "                        kernel_size=kernel_size,\n",
    "                        strides=strides,\n",
    "                        padding=padding)(x)\n",
    "    x = Concatenate()([x, out2])\n",
    "    x = conv(input_tensor=x, filters=128)\n",
    "    x = Conv2DTranspose(filters=128,\n",
    "                        kernel_size=kernel_size,\n",
    "                        strides=strides,\n",
    "                        padding=padding)(x)\n",
    "    x = Concatenate()([x, out1])\n",
    "    x = conv(input_tensor=x, filters=16)\n",
    "    x = Conv2DTranspose(filters=16,\n",
    "                        kernel_size=kernel_size,\n",
    "                        strides=strides,\n",
    "                        padding=padding)(x)\n",
    "    outputs = conv(input_tensor=x, filters=num_classes)\n",
    "    return Model(inputs=inputs, outputs=outputs, name='TransUnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
